{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEvyakanBAlL"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "TITLES = [\n",
        "    \"Artificial intelligence\",\n",
        "    \"Machine learning\",\n",
        "    \"Natural language processing\",\n",
        "    \"Deep learning\",\n",
        "    \"Neural network\",\n",
        "    \"Computer vision\",\n",
        "    \"Data mining\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_plain(title: str, timeout=20):\n",
        "    url = f\"https://en.wikipedia.org/api/rest_v1/page/plain/{title.replace(' ', '_')}\"\n",
        "    resp = requests.get(url, timeout=timeout, headers={\"User-Agent\": \"IR-Demo/1.0\"})\n",
        "    if resp.status_code == 200:\n",
        "        return resp.text\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "l-L1vtQSBV9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_documents(titles):\n",
        "    docs = {}\n",
        "    for i, title in enumerate(titles, start=1):\n",
        "        docs[i] = {\n",
        "            \"title\": title,\n",
        "            \"body\": fetch_wiki_plain(title)\n",
        "        }\n",
        "    return docs\n",
        "\n",
        "DOCUMENTS = build_documents(TITLES)"
      ],
      "metadata": {
        "id": "VlkWEuVbBYGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text: str):\n",
        "    return re.findall(r\"\\w+\", text.lower()) if text else []"
      ],
      "metadata": {
        "id": "dHHVNsx-BaTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inverted_index(documents):\n",
        "    inv = defaultdict(lambda: defaultdict(lambda: {\n",
        "        \"count\": 0,\n",
        "        \"positions\": {\"title\": [], \"body\": []},\n",
        "        \"field\": {\"title\": 0, \"body\": 0},\n",
        "    }))\n",
        "    for doc_id, obj in documents.items():\n",
        "\n",
        "        for pos, tok in enumerate(tokenize(obj[\"title\"])):\n",
        "            post = inv[tok][doc_id]\n",
        "            post[\"count\"] += 1\n",
        "            post[\"positions\"][\"title\"].append(pos)\n",
        "            post[\"field\"][\"title\"] += 1\n",
        "\n",
        "        for pos, tok in enumerate(tokenize(obj[\"body\"])):\n",
        "            post = inv[tok][doc_id]\n",
        "            post[\"count\"] += 1\n",
        "            post[\"positions\"][\"body\"].append(pos)\n",
        "            post[\"field\"][\"body\"] += 1\n",
        "    return inv\n",
        "\n",
        "INVERTED_INDEX = build_inverted_index(DOCUMENTS)"
      ],
      "metadata": {
        "id": "sMvgnLI0BcU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = len(DOCUMENTS)\n",
        "\n",
        "def compute_idf(inverted_index, N_docs):\n",
        "    idf = {}\n",
        "    for term, postings in inverted_index.items():\n",
        "        df = len(postings)\n",
        "        idf[term] = math.log(N_docs / (1 + df)) + 1\n",
        "    return idf\n",
        "\n",
        "IDF = compute_idf(INVERTED_INDEX, N)"
      ],
      "metadata": {
        "id": "xYBsrZswEUKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_documents(query, inverted_index, idf, title_boost=0.5):\n",
        "    q_tokens = tokenize(query)\n",
        "    scores = defaultdict(float)\n",
        "    for term in q_tokens:\n",
        "        if term not in inverted_index:\n",
        "            continue\n",
        "        for doc_id, data in inverted_index[term].items():\n",
        "            tf = data[\"count\"]\n",
        "            scores[doc_id] += tf * idf.get(term, 0.0)\n",
        "            if data[\"field\"][\"title\"] > 0:\n",
        "                scores[doc_id] += title_boost * data[\"field\"][\"title\"]\n",
        "    return scores"
      ],
      "metadata": {
        "id": "QxCuIAlvEYIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_all(query):\n",
        "    scores = score_documents(query, INVERTED_INDEX, IDF)\n",
        "    ranked = []\n",
        "    for doc_id, doc in DOCUMENTS.items():\n",
        "        score = scores.get(doc_id, 0.0)\n",
        "        ranked.append((doc_id, score, doc[\"title\"]))\n",
        "    ranked = sorted(ranked, key=lambda x: x[1], reverse=True)\n",
        "    return ranked"
      ],
      "metadata": {
        "id": "GVYsOe3-En1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euser_query = input(\"Enter query: \")\n",
        "\n",
        "results = search_all(user_query)\n",
        "\n",
        "print(f\"\\nQuery: {user_query}\")\n",
        "print(\"Ranking results:\")\n",
        "for rank, (doc_id, score, title) in enumerate(results, start=1):\n",
        "    print(f\"{rank}. Doc {doc_id} | {title} | score={score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CszRI92Eryl",
        "outputId": "e9f9f493-e920-4460-ffc0-62100c65da64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter query: clustering\n",
            "\n",
            "Query: clustering\n",
            "Ranking results:\n",
            "1. Doc 1 | Artificial intelligence | score=0.00\n",
            "2. Doc 2 | Machine learning | score=0.00\n",
            "3. Doc 3 | Natural language processing | score=0.00\n",
            "4. Doc 4 | Deep learning | score=0.00\n",
            "5. Doc 5 | Neural network | score=0.00\n",
            "6. Doc 6 | Computer vision | score=0.00\n",
            "7. Doc 7 | Data mining | score=0.00\n"
          ]
        }
      ]
    }
  ]
}