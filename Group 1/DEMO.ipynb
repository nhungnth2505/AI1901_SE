{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Tải và giải nén dữ liệu MovieLens\n",
        "!wget https://files.grouplens.org/datasets/moviellens/ml-latest-small.zip -q\n",
        "!unzip -q ml-latest-small.zip\n",
        "print(\"Tải và giải nén dữ liệu xong.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR7xhMhkbKU-",
        "outputId": "40a6089f-37d1-48e4-92f3-1f5b28d19336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace ml-latest-small/links.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-latest-small/tags.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-latest-small/ratings.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-latest-small/README.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-latest-small/movies.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Tải và giải nén dữ liệu xong.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.spatial.distance import euclidean\n",
        "from scipy.stats import pearsonr\n",
        "import warnings\n",
        "\n",
        "# Bỏ qua các cảnh báo RuntimeWarning (ví dụ: khi tính Pearson cho vector hằng)\n",
        "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
        "\n",
        "def tai_va_chuan_bi_du_lieu():\n",
        "    \"\"\"Tải và chuẩn bị dữ liệu từ tệp ratings.csv.\"\"\"\n",
        "    print(\"Đang tải và chuẩn bị dữ liệu...\")\n",
        "    try:\n",
        "        ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "    except FileNotFoundError:\n",
        "        print(\"Lỗi: Không tìm thấy tệp 'ml-latest-small/ratings.csv'.\")\n",
        "        print(\"Vui lòng tải và giải nén bộ dữ liệu MovieLens 100k trước.\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Giảm kích thước dữ liệu để chạy nhanh hơn (ví dụ: 1000 người dùng đầu tiên)\n",
        "    # Bỏ dòng này nếu muốn chạy trên toàn bộ 100k ratings\n",
        "    # common_users = ratings['userId'].value_counts().nlargest(1000).index\n",
        "    # ratings = ratings[ratings['userId'].isin(common_users)]\n",
        "\n",
        "    # Chia dữ liệu\n",
        "    train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Tạo ma trận user-item từ dữ liệu huấn luyện\n",
        "    # Hàng: userId, Cột: movieId, Giá trị: rating\n",
        "    train_matrix = train_df.pivot(\n",
        "        index='userId',\n",
        "        columns='movieId',\n",
        "        values='rating'\n",
        "    )\n",
        "    return train_matrix, test_df\n",
        "\n",
        "def tinh_tuong_dong_pearson(u1_ratings, u2_ratings):\n",
        "    \"\"\"Tính độ tương đồng Pearson giữa hai vector rating (pandas Series).\"\"\"\n",
        "\n",
        "    # Tìm các item mà cả hai user đều đã đánh giá\n",
        "    common_items = (u1_ratings.notna()) & (u2_ratings.notna())\n",
        "\n",
        "    # Nếu có ít hơn 2 item chung, không thể tính correlation -> 0\n",
        "    if common_items.sum() < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # Lấy rating của các item chung\n",
        "    u1_common = u1_ratings[common_items]\n",
        "    u2_common = u2_ratings[common_items]\n",
        "\n",
        "    # Tính Pearson correlation\n",
        "    corr, _ = pearsonr(u1_common, u2_common)\n",
        "\n",
        "    # Xử lý trường hợp NaN (ví dụ: nếu rating của 1 user là hằng số)\n",
        "    if np.isnan(corr):\n",
        "        return 0.0\n",
        "\n",
        "    return corr\n",
        "\n",
        "def tinh_tuong_dong_euclidean(u1_ratings, u2_ratings):\n",
        "    \"\"\"Tính độ tương đồng Euclidean giữa hai vector rating (pandas Series).\"\"\"\n",
        "\n",
        "    # Tìm các item mà cả hai user đều đã đánh giá\n",
        "    common_items = (u1_ratings.notna()) & (u2_ratings.notna())\n",
        "\n",
        "    # Nếu không có item chung -> 0\n",
        "    if common_items.sum() == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Lấy rating của các item chung\n",
        "    u1_common = u1_ratings[common_items]\n",
        "    u2_common = u2_ratings[common_items]\n",
        "\n",
        "    # Tính khoảng cách Euclidean\n",
        "    dist = euclidean(u1_common, u2_common)\n",
        "\n",
        "    # Chuyển đổi khoảng cách (distance) thành độ tương đồng (similarity)\n",
        "    # Giá trị càng gần 1 càng tốt (khi khoảng cách = 0)\n",
        "    return 1 / (1 + dist)\n",
        "\n",
        "def tao_ma_tran_tuong_dong(train_matrix, similarity_func):\n",
        "    \"\"\"Tính toán và trả về ma trận tương đồng user-user.\"\"\"\n",
        "    n_users = train_matrix.shape[0]\n",
        "    user_ids = train_matrix.index\n",
        "\n",
        "    # Tạo ma trận rỗng để lưu trữ độ tương đồng\n",
        "    sim_matrix = pd.DataFrame(\n",
        "        np.zeros((n_users, n_users)),\n",
        "        index=user_ids,\n",
        "        columns=user_ids\n",
        "    )\n",
        "\n",
        "    print(f\"Đang tính ma trận tương đồng cho {n_users} người dùng...\")\n",
        "\n",
        "    # Tính toán ma trận tam giác (đối xứng)\n",
        "    for i in range(n_users):\n",
        "        for j in range(i, n_users):\n",
        "            user_i_id = user_ids[i]\n",
        "            user_j_id = user_ids[j]\n",
        "\n",
        "            if i == j:\n",
        "                sim = 1.0\n",
        "            else:\n",
        "                sim = similarity_func(\n",
        "                    train_matrix.loc[user_i_id],\n",
        "                    train_matrix.loc[user_j_id]\n",
        "                )\n",
        "\n",
        "            sim_matrix.loc[user_i_id, user_j_id] = sim\n",
        "            sim_matrix.loc[user_j_id, user_i_id] = sim\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f\"Đã xử lý {i+1}/{n_users} người dùng.\")\n",
        "\n",
        "    return sim_matrix\n",
        "\n",
        "def du_doan_rating(user_id, item_id, train_matrix, user_means, similarity_matrix, k=30):\n",
        "    \"\"\"Dự đoán rating cho 1 user-item, sử dụng K-Nearest Neighbors.\"\"\"\n",
        "\n",
        "    # Lấy rating trung bình của user mục tiêu\n",
        "    # Nếu user mới, dùng rating trung bình toàn cục\n",
        "    global_mean = user_means.mean()\n",
        "    target_user_mean = user_means.get(user_id, global_mean)\n",
        "\n",
        "    # Lấy vector tương đồng của user_id với tất cả user khác\n",
        "    user_sims = similarity_matrix.loc[user_id]\n",
        "\n",
        "    # Lấy tất cả ratings cho item_id\n",
        "    item_ratings = train_matrix[item_id]\n",
        "\n",
        "    # Lọc ra những user đã rating item_id này\n",
        "    valid_neighbors = item_ratings.dropna()\n",
        "\n",
        "    # Lấy độ tương đồng của các \"hàng xóm\" hợp lệ này\n",
        "    neighbor_sims = user_sims.loc[valid_neighbors.index]\n",
        "\n",
        "    # Loại bỏ chính user_id (nếu có)\n",
        "    neighbor_sims = neighbor_sims.drop(user_id, errors='ignore')\n",
        "\n",
        "    # Sắp xếp và chọn K hàng xóm gần nhất\n",
        "    top_k_neighbors = neighbor_sims.nlargest(k)\n",
        "\n",
        "    # --- Tính toán dự đoán theo công thức Mean-Centered ---\n",
        "    # Prediction(u, i) = mean(u) + [ sum( sim(u, v) * (r(v, i) - mean(v)) ) / sum( |sim(u, v)| ) ]\n",
        "\n",
        "    weighted_sum = 0.0\n",
        "    sim_sum = 0.0\n",
        "\n",
        "    for neighbor_id, sim in top_k_neighbors.items():\n",
        "        # Lấy rating và rating trung bình của hàng xóm\n",
        "        neighbor_rating = valid_neighbors[neighbor_id]\n",
        "        neighbor_mean = user_means[neighbor_id]\n",
        "\n",
        "        # Công thức\n",
        "        weighted_sum += sim * (neighbor_rating - neighbor_mean)\n",
        "        sim_sum += abs(sim)\n",
        "\n",
        "    # Xử lý chia cho 0 (không có hàng xóm hợp lệ)\n",
        "    if sim_sum == 0:\n",
        "        prediction = target_user_mean\n",
        "    else:\n",
        "        prediction = target_user_mean + (weighted_sum / sim_sum)\n",
        "\n",
        "    # Đảm bảo rating nằm trong khoảng 0.5 - 5.0 (theo chuẩn MovieLens)\n",
        "    prediction = np.clip(prediction, 0.5, 5.0)\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def danh_gia_mo_hinh(test_df, train_matrix, user_means, similarity_matrix):\n",
        "    \"\"\"Đánh giá mô hình trên tập test và trả về MSE.\"\"\"\n",
        "\n",
        "    # Lọc test_df để chỉ giữ lại user và item đã có trong tập train\n",
        "    known_users = test_df['userId'].isin(train_matrix.index)\n",
        "    known_items = test_df['movieId'].isin(train_matrix.columns)\n",
        "    test_set = test_df[known_users & known_items]\n",
        "\n",
        "    print(f\"Đánh giá trên {len(test_set)} mẫu test hợp lệ...\")\n",
        "\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    for _, row in test_set.iterrows():\n",
        "        user_id = row['userId']\n",
        "        item_id = row['movieId']\n",
        "        actual_rating = row['rating']\n",
        "\n",
        "        pred_rating = du_doan_rating(\n",
        "            user_id,\n",
        "            item_id,\n",
        "            train_matrix,\n",
        "            user_means,\n",
        "            similarity_matrix\n",
        "        )\n",
        "\n",
        "        predictions.append(pred_rating)\n",
        "        actuals.append(actual_rating)\n",
        "\n",
        "    # Tính toán Mean Squared Error\n",
        "    mse = mean_squared_error(actuals, predictions)\n",
        "    return mse\n",
        "\n",
        "# --- Hàm MAIN để chạy ---\n",
        "def main():\n",
        "    train_matrix, test_df = tai_va_chuan_bi_du_lieu()\n",
        "\n",
        "    if train_matrix is None:\n",
        "        return\n",
        "\n",
        "    # Tính rating trung bình cho mỗi user (để chuẩn hóa)\n",
        "    user_means = train_matrix.mean(axis=1)\n",
        "\n",
        "    # --- 1. Đánh giá với PEARSON CORRELATION ---\n",
        "    print(\"\\n--- Bắt đầu với Pearson Correlation ---\")\n",
        "    sim_matrix_pearson = tao_ma_tran_tuong_dong(\n",
        "        train_matrix,\n",
        "        tinh_tuong_dong_pearson\n",
        "    )\n",
        "    mse_pearson = danh_gia_mo_hinh(\n",
        "        test_df,\n",
        "        train_matrix,\n",
        "        user_means,\n",
        "        sim_matrix_pearson\n",
        "    )\n",
        "    print(f\"==> MSE (Pearson): {mse_pearson:.4f}\")\n",
        "\n",
        "    # --- 2. Đánh giá với EUCLIDEAN DISTANCE ---\n",
        "    print(\"\\n--- Bắt đầu với Euclidean Similarity ---\")\n",
        "    sim_matrix_euclidean = tao_ma_tran_tuong_dong(\n",
        "        train_matrix,\n",
        "        tinh_tuong_dong_euclidean\n",
        "    )\n",
        "    mse_euclidean = danh_gia_mo_hinh(\n",
        "        test_df,\n",
        "        train_matrix,\n",
        "        user_means,\n",
        "        sim_matrix_euclidean\n",
        "    )\n",
        "    print(f\"==> MSE (Euclidean): {mse_euclidean:.4f}\")\n",
        "\n",
        "    # --- 3. Kết luận ---\n",
        "    print(\"\\n--- KẾT QUẢ SO SÁNH ---\")\n",
        "    print(f\"MSE (Pearson):   {mse_pearson:.4f}\")\n",
        "    print(f\"MSE (Euclidean): {mse_euclidean:.4f}\")\n",
        "\n",
        "    if mse_pearson < mse_euclidean:\n",
        "        print(\"Pearson Correlation cho kết quả tốt hơn (MSE thấp hơn).\")\n",
        "    else:\n",
        "        print(\"Euclidean Similarity cho kết quả tốt hơn (MSE thấp hơn).\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PolmIcfgaF1C",
        "outputId": "a9205138-2763-40b5-a671-82ae32787d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải và chuẩn bị dữ liệu...\n",
            "\n",
            "--- Bắt đầu với Pearson Correlation ---\n",
            "Đang tính ma trận tương đồng cho 610 người dùng...\n",
            "Đã xử lý 100/610 người dùng.\n",
            "Đã xử lý 200/610 người dùng.\n",
            "Đã xử lý 300/610 người dùng.\n",
            "Đã xử lý 400/610 người dùng.\n",
            "Đã xử lý 500/610 người dùng.\n",
            "Đã xử lý 600/610 người dùng.\n",
            "Đánh giá trên 19355 mẫu test hợp lệ...\n",
            "==> MSE (Pearson): 0.7956\n",
            "\n",
            "--- Bắt đầu với Euclidean Similarity ---\n",
            "Đang tính ma trận tương đồng cho 610 người dùng...\n",
            "Đã xử lý 100/610 người dùng.\n",
            "Đã xử lý 200/610 người dùng.\n",
            "Đã xử lý 300/610 người dùng.\n",
            "Đã xử lý 400/610 người dùng.\n",
            "Đã xử lý 500/610 người dùng.\n",
            "Đã xử lý 600/610 người dùng.\n",
            "Đánh giá trên 19355 mẫu test hợp lệ...\n",
            "==> MSE (Euclidean): 0.8322\n",
            "\n",
            "--- KẾT QUẢ SO SÁNH ---\n",
            "MSE (Pearson):   0.7956\n",
            "MSE (Euclidean): 0.8322\n",
            "Pearson Correlation cho kết quả tốt hơn (MSE thấp hơn).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NPKunYhMaLOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}